{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "popular-subdivision",
   "metadata": {},
   "source": [
    "This is a JupyterLab Notebook to understand \n",
    "    1. training, testing and running a TF Model\n",
    "    2. model saving/loading\n",
    "    3. TF Lite conversion\n",
    "    4. Coral TPU conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legal-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example project to train a network with the Titanic dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "capital-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the filesystem\n",
    "full_data = pd.read_csv(\"./titanic_full.csv\")\n",
    "\n",
    "# Change some column names\n",
    "full_data = full_data.rename(columns = {\"pclass\" : \"ticketClass\"})\n",
    "\n",
    "# Drop some columns which are not needed for prediction (just to keep it simple)\n",
    "# we don't aim for best prediction results (but a small example :-))\n",
    "full_data = full_data.drop(['name','ticket','age','cabin','embarked', 'home.dest', 'body', 'boat', 'fare'],axis =1)\n",
    "\n",
    "# Transforming sex column values using label encoder\n",
    "label_encoder_sex = LabelEncoder()\n",
    "full_data.iloc[:,2]  = label_encoder_sex.fit_transform(full_data.iloc[:,2])\n",
    "\n",
    "# Rearranging columns\n",
    "full_data = full_data[['sex', 'sibsp','parch','ticketClass','survived']]\n",
    "\n",
    "# Split into input and result data\n",
    "x_full = full_data.iloc[:,0:4]\n",
    "y_full = full_data.iloc[:,4]\n",
    "\n",
    "# Normalize the data\n",
    "sc = StandardScaler()\n",
    "x_full = sc.fit_transform(x_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "resident-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and test datasets\n",
    "x_train, x_test, y_train, y_test = tts(x_full, y_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brazilian-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup of our model by the functional API of Keras\n",
    "inputs = keras.Input(shape=(4))\n",
    "x = layers.Dense(3, activation=\"relu\", name=\"first_layer\")(inputs)\n",
    "x = layers.Dense(2, activation=\"relu\", name=\"second_layer\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "perceived-anchor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results of trained model:\n",
      "33/33 - 0s - loss: 0.5037 - accuracy: 0.7896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5037394165992737, 0.7896341681480408]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training of the model\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=100, verbose=0)\n",
    "print(\"Test results of trained model:\")\n",
    "model.evaluate(x_test, y_test, batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "laughing-legislature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of survival:  0.12868789\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a new single input:\n",
    "y = model.predict(np.array([[0.74349692, -0.47908676, -0.4449995, 0.84191642]]))\n",
    "print(\"Likelihood of survival: \", y[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "optional-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights of the model onto the file-system\n",
    "model.save_weights(\"./saved_weights/titanic_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "coated-violin",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1721c06bbc8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./saved_weights/titanic_weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf-projects/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2220\u001b[0m           '`load_weights` requires h5py when loading weights from HDF5.')\n\u001b[1;32m   2221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2222\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   2223\u001b[0m           \u001b[0;34m'Unable to load weights saved in HDF5 format into a subclassed '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2224\u001b[0m           \u001b[0;34m'Model which has not created its variables yet. Call the Model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights."
     ]
    }
   ],
   "source": [
    "model2 = keras.Model()\n",
    "model2.load_weights(\"./saved_weights/titanic_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "imperial-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of survival:  0.12868789\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(4))\n",
    "x = layers.Dense(3, activation=\"relu\", name=\"first_layer\")(inputs)\n",
    "x = layers.Dense(2, activation=\"relu\", name=\"second_layer\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model2 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model2.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model2.load_weights(\"./saved_weights/titanic_weights.h5\")\n",
    "# Test the model with a new single input:\n",
    "y = model2.predict(np.array([[0.74349692, -0.47908676, -0.4449995, 0.84191642]]))\n",
    "print(\"Likelihood of survival: \", y[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cultural-holocaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./titanic_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"./titanic_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "treated-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of survival:  0.12868789\n"
     ]
    }
   ],
   "source": [
    "#Loading the saved model and testing the successful load\n",
    "model3 = keras.models.load_model(\"./titanic_model/\")\n",
    "# Test the model with a new single input:\n",
    "y = model2.predict(np.array([[0.74349692, -0.47908676, -0.4449995, 0.84191642]]))\n",
    "print(\"Likelihood of survival: \", y[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "exempt-screw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjsbok4il/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjsbok4il/assets\n"
     ]
    }
   ],
   "source": [
    "# Converting the saved model into TensorFlow lite\n",
    "model_for_tflite = keras.models.load_model(\"./titanic_model/\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_tflite)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the new TF lite model\n",
    "with open('titanic-model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "turned-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of survival:  0.12868789\n"
     ]
    }
   ],
   "source": [
    "# Load the TF-Lite model and test inference\n",
    "interpreter = tf.lite.Interpreter(model_path='titanic-model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Create the input data\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array([[0.74349692, -0.47908676, -0.4449995, 0.84191642]], dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Call the model\n",
    "interpreter.invoke()\n",
    "\n",
    "# Return the output data\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Likelihood of survival: \", output_data[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "related-freeware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjnd20mfq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjnd20mfq/assets\n"
     ]
    }
   ],
   "source": [
    "# Model quantization as preparation to load the trained model onto Coral TPU\n",
    "# https://www.tensorflow.org/lite/performance/post_training_quantization\n",
    "\n",
    "model_for_tflite_tpu = keras.models.load_model(\"./titanic_model/\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_tflite_tpu)\n",
    "\n",
    "# Create representative dataset\n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = x_test\n",
    "        yield [data.astype(np.float32)]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Dataset to find the right dimensions (\"normalization\") for the integers\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "# Compile quantized model for Coral TPU\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "# Save the new quantized TF lite model\n",
    "with open('titanic-model_quantized.tflite', 'wb') as f:\n",
    "  f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-vegetarian",
   "metadata": {},
   "source": [
    "Install the EdgeTPU compiler by:\n",
    "sudo apt-get install edgetpu-compiler\n",
    "\n",
    "Then run the compiler on the model:\n",
    "edgetpu_compiler titanic-model_quantized.tflite \n",
    "\n",
    "A new file will be created: titanic-model_quantized_edgetpu.tflite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
